{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Deep Mining Spam Email Detection Project\n",
    "\n",
    "SOFE 4620U - Machine Learning & Data Mining Final Project\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement\n",
    "\n",
    "The problem we wish to address is the filtering of spam emails from one's personal email address. Spam is a common issue for most individuals as various sites leak user’s email information to nefarious companies who then “spam” the users email with repetitive and often inappropriate advertisements. Although solutions for this problem already exist, we wish to build an email filtering system with categorization of spam emails to further our understanding of natural language processing and machine learning as a whole. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "import enchant\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"spam_nospam.csv\", header=None)\n",
    "df[:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset information and statistics\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:\"Type\", 1:\"Message\", 2:\"Filename\"})\n",
    "df = df.drop(columns={\"Filename\"})\n",
    "df = df.drop(0)\n",
    "df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Length\"] = df[\"Message\"].apply(len)\n",
    "df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10, 5))\n",
    "x = df.Type.value_counts()\n",
    "sns.countplot(x = \"Type\", data = df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_content_tags = [\"html\", \"body\", \"head\", \"footer\", \"b\", \"br\", \"font\", \"http\", \"com\", \"www\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation\n",
    "df[\"Message\"] = df[\"Message\"].str.replace(\"\\W\", \" \", regex=True)\n",
    "\n",
    "# Lower casing all letters\n",
    "df[\"Message\"] = df[\"Message\"].str.lower()\n",
    "\n",
    "df[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_spam = df[df.Type == 0]\n",
    "#spam = df[df.Type == 1]\n",
    "\n",
    "#non_spam_text = \" \".join(non_spam.Message.to_numpy().tolist())\n",
    "#spam_text = \" \".join(spam.Message.to_numpy().tolist())\n",
    "\n",
    "non_spam_amount = []\n",
    "spam_amount = []\n",
    "counter = 0\n",
    "\n",
    "# Add spam and non-spam messages to their own array list\n",
    "\n",
    "for i in df[\"Type\"]:\n",
    "    if (i == \"0\"):\n",
    "        non_spam_amount.append(df[\"Message\"].iloc[counter])\n",
    "    elif (i == \"1\"):\n",
    "        spam_amount.append(df[\"Message\"].iloc[counter])\n",
    "    counter = counter + 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Non-Spam Words\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each non-spam message into individual words and add them to an array list\n",
    "\n",
    "for i in non_spam_amount:\n",
    "    split_words_nonspam = i.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array list that contains cleaned non-spam words\n",
    "word_array_nonspam = []\n",
    "j = 0\n",
    "\n",
    "# Further clean words within non-spam array by removing stop words and html tag related words\n",
    "\n",
    "while j <= len(split_words_nonspam):\n",
    "    for words in split_words_nonspam:\n",
    "        \n",
    "        # Remove stop words such as \"a\", \"the\", ...\n",
    "        if words.lower() in stopwords.words(\"english\"):\n",
    "            split_words_nonspam.remove(words)\n",
    "        \n",
    "        # Remove html tag words such as \"html\", \"br\", ...\n",
    "        if words in html_content_tags or len(words) <= 1:\n",
    "            continue\n",
    "        \n",
    "        #d = enchant.Dict(\"en_US\")\n",
    "        #if d.check(words) == False:\n",
    "            #continue\n",
    "            \n",
    "        word_array_nonspam.append(words)\n",
    "    j = j + 1\n",
    "    \n",
    "# Utilize counter function to determine most common non-spam words\n",
    "word_set_nonspam = Counter(word_array_nonspam)\n",
    "frequent_words_nonspam = word_set_nonspam.most_common(15)\n",
    "print(frequent_words_nonspam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains cleaned non-spam words\n",
    "word_array_nonspam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most occurring non-spam words\n",
    "nonspam_amount = pd.DataFrame(frequent_words_nonspam)\n",
    "nonspam_amount = nonspam_amount.rename(columns={0:\"Words\", 1:\"Occurrences\"})\n",
    "nonspam_amount"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Spam Words\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split each spam message into individual words and add them to an array list\n",
    "for i in spam_amount:\n",
    "    split_words_spam = i.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array list that contains cleaned spam words\n",
    "word_array_spam = []\n",
    "k = 0\n",
    "\n",
    "# Further clean words within spam array by removing stop words and html tag related words\n",
    "\n",
    "while k <= len(split_words_spam):\n",
    "    for words in split_words_spam:\n",
    "        \n",
    "        # Remove stop words such as \"a\", \"the\", ...\n",
    "        if words.lower() in stopwords.words(\"english\"):\n",
    "            split_words_spam.remove(words)\n",
    "            \n",
    "        # Remove html tag words such as \"html\", \"br\", ...\n",
    "        if words in html_content_tags or len(words) <= 1:\n",
    "            continue\n",
    "        \n",
    "        #d = enchant.Dict(\"en_US\")\n",
    "        #if d.check(words) == False:\n",
    "            #continue\n",
    "            \n",
    "        word_array_spam.append(words)\n",
    "    k = k + 1\n",
    "\n",
    "# Utilize counter function to determine most common spam words\n",
    "word_set_spam = Counter(word_array_spam)\n",
    "frequent_words_spam = word_set_spam.most_common(15)\n",
    "print(frequent_words_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contains cleaned spam words\n",
    "word_array_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display most occurring spam words\n",
    "spam_amount = pd.DataFrame(frequent_words_spam)\n",
    "spam_amount = spam_amount.rename(columns={0:\"Words\", 1:\"Occurrences\"})\n",
    "spam_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_array_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_array_nonspam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Update Messages within Table\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_message = 1\n",
    "max_message_amount = len(df[\"Message\"])\n",
    "\n",
    "# Clean and update the messages within the table\n",
    "\n",
    "for message in df[\"Message\"]:\n",
    "    # Split the message into an array of words\n",
    "    message_new = message.split()\n",
    "    \n",
    "    # Cycle through the array of words\n",
    "    for words in message_new:\n",
    "        \n",
    "        # Remove stop words such as \"a\", \"the\", ...\n",
    "        if words in stopwords.words(\"english\"):\n",
    "            message_new.remove(words)\n",
    "\n",
    "    # Update the message in the table with the new message that contains no stop words\n",
    "    df.loc[counter_message, \"Message\"] = ' '.join(message_new)\n",
    "    message_new.clear()\n",
    "    counter_message = counter_message + 1\n",
    "    \n",
    "    # If reached end of the table\n",
    "    if (counter_message == max_message_amount):\n",
    "        break\n",
    "\n",
    "# Update the length of each message\n",
    "df[\"Length\"] = df[\"Message\"].str.len()\n",
    "\n",
    "# Save to csv \n",
    "df[:].to_csv('cleaned_data.csv', index=False)\n",
    "df[:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most common words with wordcloud\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_words = \" \".join(list(df[df[\"Type\"] == \"1\"][\"Message\"]))\n",
    "spam_wordcloud = WordCloud(width = 512, height = 512).generate(spam_words)\n",
    "plt.figure(figsize = (10, 8), facecolor=\"k\")\n",
    "plt.imshow(spam_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_spam_words = \" \".join(list(df[df[\"Type\"] == \"0\"][\"Message\"]))\n",
    "non_spam_wordcloud = WordCloud(width = 512, height = 512).generate(non_spam_words)\n",
    "plt.figure(figsize = (10, 8), facecolor=\"k\")\n",
    "plt.imshow(non_spam_wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Different Models \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Message</th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>dear homeowner interest rates at lowest point ...</td>\n",
       "      <td>447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>attention is must computer users new special p...</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>multi part message mime format _nextpart_000_1...</td>\n",
       "      <td>4479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>important information new domain names finally...</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bottom line give away cd free people like 80 1...</td>\n",
       "      <td>1267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5791</th>\n",
       "      <td>0</td>\n",
       "      <td>m one the 30 000 it working well week the tes ...</td>\n",
       "      <td>693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5792</th>\n",
       "      <td>0</td>\n",
       "      <td>damien morton quoted w3c approves html 4 emoti...</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5793</th>\n",
       "      <td>0</td>\n",
       "      <td>mon 2002 07 22 06 50 che wrote thats correct l...</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5794</th>\n",
       "      <td>0</td>\n",
       "      <td>upon time manfred wrote would like install rpm...</td>\n",
       "      <td>1012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5795</th>\n",
       "      <td>0</td>\n",
       "      <td>if you run pick  and then use the  new ftoc  b...</td>\n",
       "      <td>913</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5796 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type                                            Message  Length\n",
       "0        1  dear homeowner interest rates at lowest point ...     447\n",
       "1        1  attention is must computer users new special p...     855\n",
       "2        1  multi part message mime format _nextpart_000_1...    4479\n",
       "3        1  important information new domain names finally...     882\n",
       "4        1  bottom line give away cd free people like 80 1...    1267\n",
       "...    ...                                                ...     ...\n",
       "5791     0  m one the 30 000 it working well week the tes ...     693\n",
       "5792     0  damien morton quoted w3c approves html 4 emoti...     199\n",
       "5793     0  mon 2002 07 22 06 50 che wrote thats correct l...     322\n",
       "5794     0  upon time manfred wrote would like install rpm...    1012\n",
       "5795     0  if you run pick  and then use the  new ftoc  b...     913\n",
       "\n",
       "[5796 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data = pd.read_csv('cleaned_data.csv')\n",
    "cleaned_data[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4636, 93895)\n",
      "X_test shape: (1160, 93895)\n"
     ]
    }
   ],
   "source": [
    "X = cleaned_data['Message']  # message column\n",
    "y = cleaned_data['Type']  # type column (spam/ham)\n",
    "\n",
    "# split the data into training and testing sets with a 80:20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Vectorize the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "# check the shapes of the resulting vectors\n",
    "print(\"X_train shape:\", X_train_vectorized.shape)\n",
    "print(\"X_test shape:\", X_test_vectorized.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.925\n",
      "Precision: 0.987460815047022\n",
      "Recall: 0.7914572864321608\n",
      "F1: 0.8786610878661089\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Train a Naive Bayes classifier\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict the class of new emails\n",
    "y_pred = nb.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Support Vector Machines | SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9922413793103448\n",
      "Precision: 0.9899244332493703\n",
      "Recall: 0.9874371859296482\n",
      "F1: 0.988679245283019\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm = SVC(kernel='linear')\n",
    "svm.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict the class of new emails\n",
    "y_pred = svm.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9801724137931035\n",
      "Precision: 0.9844961240310077\n",
      "Recall: 0.957286432160804\n",
      "F1: 0.9707006369426752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Train a Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict the class of new emails\n",
    "y_pred = rf.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors | KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.971551724137931\n",
      "Precision: 0.9573934837092731\n",
      "Recall: 0.9597989949748744\n",
      "F1: 0.958594730238394\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Train a KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict the class of new emails\n",
    "y_pred = knn.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9827586206896551\n",
      "Precision: 0.9846153846153847\n",
      "Recall: 0.964824120603015\n",
      "F1: 0.9746192893401016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Train a Logistic Regression classifier\n",
    "lr = LogisticRegression(solver='liblinear')\n",
    "lr.fit(X_train_vectorized, y_train)\n",
    "\n",
    "# Predict the class of new emails\n",
    "y_pred = lr.predict(X_test_vectorized)\n",
    "\n",
    "# Evaluate Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# print the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geopandas_testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d86e3b739d74aff4eb03105875b1929a07e9c1e655cfa06ddfb4ec5c2bf4112e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
